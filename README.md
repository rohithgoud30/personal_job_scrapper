# Personal Job Scraper

A powerful, AI-powered CLI tool to scrape job listings from multiple sites, filter them intelligently, and save only the best matches.

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/rohithgoud30/personal_job_scrapper.git
cd personal_job_scrapper

# Install dependencies
npm install
npx playwright install chromium

# Configure environment
cp .env.example .env
# Edit .env and add your ZAI_API_KEY

# Run a scraper
npm start -- --site=corptocorp
```

## ğŸ“‹ Prerequisites

- **Node.js** v18 or higher
- **Git**
- **Zhipu AI API Key** ([Get one here](https://open.bigmodel.cn/))

## âš™ï¸ Configuration

### 1. Environment Variables

Copy `.env.example` to `.env`:

```bash
cp .env.example .env
```

Edit `.env` with your settings:

```env
ZAI_API_KEY=your-z-ai-key
ZAI_BASE_URL=https://api.z.ai/api/coding/paas/v4
KEYWORD_BATCH_SIZE=5
TEST_RUN_DATE=
```

| Variable             | Description                                                  | Required           |
| -------------------- | ------------------------------------------------------------ | ------------------ |
| `ZAI_API_KEY`        | Your Zhipu AI API key for job filtering                      | âœ… Yes             |
| `ZAI_BASE_URL`       | API endpoint (default shown above)                           | âŒ No              |
| `KEYWORD_BATCH_SIZE` | Number of parallel keyword searches                          | âŒ No (default: 5) |
| `TEST_RUN_DATE`      | Backfill date (YYYY-MM-DD format, leave empty for live runs) | âŒ No              |

### 2. Site Configuration

All site-specific settings are in `config.json`:

- Search keywords
- CSS selectors
- Crawl delays
- AI filtering rules

## ğŸ¯ Usage

### Run Individual Sites

```bash
# CorpToCorp (C2C jobs, OPT/STEM OPT friendly)
npm start -- --site=corptocorp

# Kforce (Contract roles)
npm start -- --site=kforce

# Randstad USA (Contract jobs)
npm start -- --site=randstadusa
```

### Run All Sites

```bash
npm start
```

### Advanced Options

```bash
# Re-run AI evaluation on existing session
npm start -- --site=corptocorp --session=session-2025-11-19T03-23-05-227Z

# Skip delays between keyword batches (use sparingly)
npm start -- --site=corptocorp --fast

# Backfill a specific date
TEST_RUN_DATE=2025-11-14 npm start -- --site=kforce
```

## ğŸ“Š Supported Sites

| Site           | Speed          | Visa Filter  | Notes                                    |
| -------------- | -------------- | ------------ | ---------------------------------------- |
| **CorpToCorp** | âš¡âš¡âš¡ Fastest | OPT/STEM OPT | C2C listings, auto-sorts by date         |
| **Kforce**     | âš¡ Slower      | Standard     | Contract roles, 30s crawl-delay required |
| **Randstad**   | âš¡âš¡ Fast      | Standard     | Contract/Temp jobs                       |

## ğŸ§  How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Scraping   â”‚ â†’ Launch browser, search keywords, extract listings
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI Filter 1 â”‚ â†’ Remove irrelevant titles (Data/BI/Legacy/QA)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI Filter 2 â”‚ â†’ Evaluate full job descriptions
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   âœ“ Tech stack match (React/Node/Java/Python)
       â†“          âœ“ Experience: 5 to <6 years
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   âœ“ Visa requirements (OPT/STEM for CorpToCorp)
â”‚   Output    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â†’ data/<site>/<date>/new_jobs_<date>.csv
```

### AI Filtering Rules

**Stage 1: Title Filter** (Model: `glm-4.6`)

- Removes: Data Engineer, BI/Analytics, QA/SDET, .NET, C#, Go, Legacy Tech
- Keeps: Modern web/full-stack roles

**Stage 2: Detail Evaluation** (Model: `glm-4.5-Air`)

- âœ… **Tech Stack**: React, Angular, Next.js, Node.js, Java/Spring Boot, Python/FastAPI
- âœ… **Experience**: 5 to <6 years (e.g., "5 years", "1-5 years", "5+")
- âœ… **Visa** (CorpToCorp): OPT, STEM OPT, or no restrictions
- âŒ **Rejects**: 6+ years, H1B/USC-only, non-web stacks

## ğŸ“‚ Output Structure

```
data/
â””â”€â”€ corptocorp.org/
    â””â”€â”€ 11_18_2025/
        â”œâ”€â”€ new_jobs_11_18_2025.csv          # Final approved jobs
        â”œâ”€â”€ seen.json                         # Deduplication store
        â””â”€â”€ sessions/
            â””â”€â”€ session-2025-11-19T.../
                â””â”€â”€ roles/
                    â””â”€â”€ new_roles.csv         # Staged jobs (pre-AI)
```

### CSV Format

```csv
site,title,company,location,posted,url,job_id,scraped_at
corptocorp,Java Full Stack Engineer,CorpToCorp,,2025-11-18 19:12:00,https://...,10:23 PM ET
```

## ğŸ“– Documentation

Detailed architecture and logic for each scraper:

- ğŸ“˜ [CorpToCorp Architecture](docs/architecture/corptocorp.md)
- ğŸ“— [Kforce Architecture](docs/architecture/kforce.md)
- ğŸ“™ [Randstad Architecture](docs/architecture/randstadusa.md)

## ğŸ”§ Troubleshooting

### "No sites matched the provided --site filter"

- Check that the site key is correct: `corptocorp`, `kforce`, or `randstadusa`
- Ensure `config.json` is valid JSON

### "ProcessSingleton" error

- Close any existing browser windows using the same profile
- Wait 30 seconds and try again

### No jobs found

- Check `config.json` â†’ `search.criteria.searchKeywords`
- Verify `postedTodayOnly` setting (set to `false` for testing)
- Check if site structure changed (inspect selectors)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/new-site`)
3. Commit your changes (`git commit -m 'feat: add new site scraper'`)
4. Push to the branch (`git push origin feature/new-site`)
5. Open a Pull Request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- [Playwright](https://playwright.dev/) for browser automation
- [Zhipu AI](https://open.bigmodel.cn/) for intelligent job filtering
- [TypeScript](https://www.typescriptlang.org/) for type safety
